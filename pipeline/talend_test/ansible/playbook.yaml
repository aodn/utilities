

- name: test talend
  hosts: "{{hosts}}"
  gather_facts: no

  roles:
    - talend_test

  vars_files:
    - ../global_vars.yaml

  tasks:

### Run Pipeline

  ### setup

    - name: drop objects in schema
      become: yes
      become_user: postgres
      command: psql -d harvest -c "select drop_objects_in_schema('"{{ item.name }}"');"
      register: truncate_schema
      with_items: "{{ database_schemas }}"
      when: create_schema == true


    - name: run talend liqui
      become: yes
      become_user: talend
      shell: |
        talend_regex="___"{{ item }}"___";
        /usr/local/talend/bin/talend-trigger -c /usr/local/talend/etc/trigger.conf --delete -f $talend_regex,$talend_regex
      with_items: "{{ talend_jobs }}"
      when: create_schema == true


    - name: remove logs for pipline v1 and harvester types
      become: yes
      become_user: root
      shell: "rm -rf {{ talend_log_dir }}/*"
      when: (type == 'pipeline_version_1') or (type == 'harvester')


    - name: check that the talend log file exists
      stat:
        path: "{{ talend_log_file }}"
      register: log_file
      when: type == 'pipeline_version_2'


    - name: truncate pipeline 2 log
      become: yes
      become_user: root
      shell: "> {{ talend_log_file }}"
      when: (type == 'pipeline_version_2') and (log_file.stat.exists == true)

    - name: create directories
      become: yes
      become_user: root
      file:
        path: "{{ item.path }}"
        state: directory
        owner: "{{ item.owner }}"
        group: "{{ item.group }}"
      with_items: "{{ dirs }}"
      when: dirs is defined

  ### copy files to remote locations (last file itemised in config
  ###  may be for the incoming dir which will kick off the process

    - name: copy files to target directories
      become: yes
      become_user: root
      copy:
        src: "{{ input_files_dir }}/{{ name }}/{{ item.file }}"
        dest: "{{ item.dest }}"
        owner: projectofficer
        group: projectofficer
        mode: a+w
      with_items: "{{ files }}"
      when: (type == 'pipeline_version_1') or (type == 'pipeline_version_2')


    - name: execute script
      become: yes
      become_user: talend
      command: "{{ exec_shell_script }}"
      when: type == 'harvester'


  ### wait for pipeline to finish

    - name: wait for pipeline 1 processing to complete
      command: "grep -r 'file(s)  OK'  {{ talend_log_dir }}"
      register: task_result
      delay: 5
      retries: 500
      until: task_result.rc == 0
      with_items: "{{ talend_jobs }}"
      when: type == 'pipeline_version_1'


    - name: wait for pipeline 2 processing to complete
      wait_for:
        path: "{{ talend_log_file }}"
        search_regex: FILE_SUCCESS
        timeout: 800
      when: type == 'pipeline_version_2'


    - name: wait for harvester-type processing to complete
      command: "grep -r 'log4j:WARN Please initialize the log4j system properly'  {{ talend_log_dir }}"
      register: task_result
      delay: 5
      retries: 100
      until: task_result.rc == 0
      with_items: "{{ talend_jobs }}"
      when: type == 'harvester'


### Query database and download result

    - set_fact:
       pgsql_output_dir: "/tmp/{{ ansible_ssh_host }}/{{ name }}"


    - name: remove pgsql_output_dir output dir
      become: yes
      become_user: root
      file: path={{ pgsql_output_dir }} state=absent


    - name: create dirs for pgsql output
      file: path={{ pgsql_output_dir }}/{{ item.name }} state=directory mode="a+w"
      with_items: "{{ database_schemas }}"


    - name: remove pgsql shell script file
      become: yes
      become_user: root
      file: path={{ pgsql_queries_shell_script }} state=absent


    - name: sql select queries
      pgsql_statement_gen:
        schema_obj: "{{ item }}"
        pgsql_output_dir: "{{ pgsql_output_dir }}"
        pgsql_queries_shell_script: "{{ pgsql_queries_shell_script }}"
      with_items: "{{ database_schemas }}"


    - name: run queries
      become: yes
      become_user: postgres
      command: "psql -d harvest -f {{ pgsql_queries_shell_script }}"


    - name: compress query result directory
      become: yes
      become_user: root
      archive:
        path: "/tmp/{{ ansible_ssh_host }}"
        dest: /tmp/query_results.tgz


    - set_fact:
       local_tmp_path: "/tmp/{{ ansible_ssh_host }}/query_results.tgz"


    - name: fetch query results to local
      fetch:
        src: /tmp/query_results.tgz
        dest: "{{ local_tmp_path }}"
        flat: true
        mode: 0774


    - name: unzip query results on localhost
      unarchive:
        src: "{{ local_tmp_path }}"
        dest: ../query_results
      delegate_to: localhost
