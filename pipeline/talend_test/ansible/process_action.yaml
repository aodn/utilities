
### process action sub-playbook. adds input files and waits for processing to complete


- name: process_action object
  debug:
    msg: "{{ action_item }}"


# remove/truncate logs

- name: remove pipeline 1 log
  become: yes
  become_user: root
  shell: "> {{ pipeline_1_process_log }}"
  when: type == 'pipeline_version_1'


- name: remove logs for pipline v1
  become: yes
  become_user: root
  shell: "rm -rf {{ talend_log_dir }}/*"
  when: (type == 'pipeline_version_1')


- name: check that the talend log file exists
  stat:
    path: "{{ talend_log_file }}"
  register: log_file
  when: type == 'pipeline_version_2'


- name: truncate pipeline 2 log
  become: yes
  become_user: root
  shell: "> {{ talend_log_file }}"
  when: (type == 'pipeline_version_2') and (log_file.stat.exists == true)


# copy files to destination (kicks off processing for pipeline types) for ADD/UPDATE actions

- name: copy files to target directories
  become: yes
  become_user: root
  copy:
    src: "../input_files/{{ name }}/{{ item.local_file }}"
    dest: "{{ item.dest }}/{{ item.remote_file if item.remote_file is defined else item.local_file }}"
    owner: projectofficer
    group: projectofficer
    mode: a+w
  loop: "{{ action_item.files }}"
  when: action_item.type == 'ADD' or action_item.type == 'UPDATE'


- name: list s3 objects to delete
  shell: "aws s3 ls --recursive s3://{{ host_bucket }}/{{ action_item.path }} | awk '{print $4}'"
  register: objects_list
  when: (type == 'pipeline_version_1' or type == 'pipeline_version_2') and
        action_item.type == 'DELETE' and action_item.path is defined
  delegate_to: localhost


- set_fact:
    delete_list: "{{ [ action_item.file ] }}"
  when: (type == 'pipeline_version_1' or type == 'pipeline_version_2') and
        action_item.type == 'DELETE' and action_item.file is defined


- set_fact:
    delete_list: "{{ objects_list.stdout_lines|list }}"
  when: objects_list.stdout_lines is defined


  # note: the po_s3_del command succeeds even when it tries to delete a key that doesn't exist
  # (fails if given a 'folder' i.e. object ending with '/'
- name: delete files using po_s3_del
  become: yes
  become_user: root
  command: "sudo -u projectofficer -i po_s3_del {{ item }}"
  with_items: "{{ delete_list }}"
  when: delete_list is defined


- name: execute script
  become: yes
  become_user: talend
  shell: "{{ exec_shell_script.script }}"
  when: type == 'harvester'


### wait for pipeline to finish

- set_fact:
    start_time: "{{ lookup('pipe','date \"+%Y-%m-%d %H:%M:%S\"') }}"


- name: wait for pipeline 1 ADD and UPDATE processing to complete
  command: "grep -r 'file(s)  OK'  {{ talend_log_dir }}"
  register: task_result
  delay: 5
  retries: 500
  until: task_result.rc == 0
  when: type == 'pipeline_version_1' and
        (action_item.type == 'ADD' or action_item.type == 'UPDATE')


- name: wait for pipeline 2 ADD and UPDATE processing to complete
  wait_for:
    path: "{{ talend_log_file }}"
    search_regex: FILE_SUCCESS
    timeout: 800
  when: type == 'pipeline_version_2' and
        (action_item.type == 'ADD' or action_item.type == 'UPDATE')

- name: wait for harvester-type processing to complete
  wait_for:
    path: "{{ talend_log_file }}"
    search_regex: ^finish;
    timeout: 800
  when:  type == 'harvester' and exec_shell_script.asynchronous|default(false)

- set_fact:
    end_time: "{{ lookup('pipe','date \"+%Y-%m-%d %H:%M:%S\"') }}"


- set_fact:
    elapsed_time: "{{ (end_time|to_datetime - start_time|to_datetime).seconds|string }}"


- name: append line to time_profile.csv
  lineinfile:
    create: true
    path: ../time_profile.csv
    line: "{{ name }},{{ hosts }},{{ action_item.type }},{{ elapsed_time }}"
    insertafter: EOF
  delegate_to: localhost
