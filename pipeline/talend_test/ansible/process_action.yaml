
### process action sub-playbook. adds input files and waits for processing to complete


- name: process_action object
  debug:
    msg: "{{ action_item }}"


# remove/truncate logs

- name: remove pipeline 1 log
  become: yes
  become_user: root
  shell: "> {{ pipeline_1_process_log }}"
  when: type == 'pipeline_version_1'


- name: remove logs for pipline v1 and harvester types
  become: yes
  become_user: root
  shell: "rm -rf {{ talend_log_dir }}/*"
  when: (type == 'pipeline_version_1') or (type == 'harvester')


- name: check that the talend log file exists
  stat:
    path: "{{ talend_log_file }}"
  register: log_file
  when: type == 'pipeline_version_2'


- name: truncate pipeline 2 log
  become: yes
  become_user: root
  shell: "> {{ talend_log_file }}"
  when: (type == 'pipeline_version_2') and (log_file.stat.exists == true)


# copy files to destination (kicks off processing) for ADD/UPDATE actions

- name: copy files to target directories
  become: yes
  become_user: root
  copy:
    src: "../input_files/{{ name }}/{{ item.local_file }}"
    dest: "{{ item.dest }}/{{ item.remote_file if item.remote_file is defined else item.local_file }}"
    owner: projectofficer
    group: projectofficer
    mode: a+w
  loop: "{{ action_item.files }}"
  when: (type == 'pipeline_version_1' or type == 'pipeline_version_2') and
        (action_item.type == 'ADD' or action_item.type == 'UPDATE')


  # note: the po_s3_del command succeeds even when it tries to delete a key that doesn't exist
  # (fails if given a 'folder' i.e. object ending with '/'
- name: delete files using po_s3_del
  become: yes
  become_user: root
  command: "sudo -u projectofficer -i po_s3_del {{ action_item.file }}"
  register: po_s3_del
  when: (type == 'pipeline_version_1' or type == 'pipeline_version_2') and
        action_item.type == 'DELETE'


- name: execute script
  become: yes
  become_user: talend
  command: "{{ exec_shell_script }}"
  when: type == 'harvester'


### wait for pipeline to finish

- set_fact:
    start_time: "{{ lookup('pipe','date \"+%Y-%m-%d %H:%M:%S\"') }}"


- name: wait for pipeline 1 ADD and UPDATE processing to complete
  command: "grep -r 'file(s)  OK'  {{ talend_log_dir }}"
  register: task_result
  delay: 5
  retries: 500
  until: task_result.rc == 0
  when: type == 'pipeline_version_1' and
        (action_item.type == 'ADD' or action_item.type == 'UPDATE')


- name: wait for pipeline 2 ADD and UPDATE processing to complete
  wait_for:
    path: "{{ talend_log_file }}"
    search_regex: FILE_SUCCESS
    timeout: 800
  when: type == 'pipeline_version_2' and
        (action_item.type == 'ADD' or action_item.type == 'UPDATE')


- name: wait for harvester-type processing to complete
  command: "grep -r 'log4j:WARN Please initialize the log4j system properly'  {{ talend_log_dir }}"
  register: task_result
  delay: 5
  retries: 100
  until: task_result.rc == 0
  with_items: "{{ talend_jobs }}"
  when: type == 'harvester'


- set_fact:
    end_time: "{{ lookup('pipe','date \"+%Y-%m-%d %H:%M:%S\"') }}"


- set_fact:
    elapsed_time: "{{ (end_time|to_datetime - start_time|to_datetime).seconds|string }}"


- name: append line to time_profile.csv
  lineinfile:
    create: true
    path: ../time_profile.csv
    line: "{{ name }},{{ hosts }},{{ action_item.type }},{{ elapsed_time }}"
    insertafter: EOF
  delegate_to: localhost
